# v1.7.0 Implementation Guide: Memory Versioning, Schema, and Dependencies

**Version**: 1.7.0

**Date**: 2025-12-09

**Audience**: Developers maintaining and extending the versioning/schema/dependency features

---

## Architecture Overview

The v1.7.0 features follow the existing 3-tier layered architecture:

```
┌─────────────────────────────────────────────────┐
│         MCP Tools Layer (11 new tools)           │
│  versioning_tools, schema_tools, dependency_tools│
└─────────────────┬───────────────────────────────┘
                  │
┌─────────────────▼───────────────────────────────┐
│      Service Layer (3 new services)              │
│  VersioningService, SchemaService, DependencyService│
└─────────────────┬───────────────────────────────┘
                  │
┌─────────────────▼───────────────────────────────┐
│    Repository Layer (extended MemoryRepository)  │
│  save_version, get_version_history, rollback_to_version│
└─────────────────┬───────────────────────────────┘
                  │
┌─────────────────▼───────────────────────────────┐
│    Database Layer (3 new tables, migration v6)   │
│  memory_versions, memory_schemas, dependency_notifications│
└─────────────────────────────────────────────────┘
```

---

## Detailed Component Guide

### 1. Models Layer

#### `src/models/versioning.py`

**Purpose**: Data models for version history tracking

**Key Classes**:
- `MemoryVersion` - Single version snapshot
  - Fields: id, memory_id, version, content, tags, metadata, created_at, change_reason
  - Represents immutable state at specific version number

- `VersionDiff` - Comparison between two versions
  - Fields: from_version, to_version, changed_fields, diff_summary
  - Shows what changed between versions

- `VersionHistory` - Complete history for a memory
  - Fields: memory_id, versions[], current_version, total_versions
  - Pagination support via limit parameter

**Usage**:
```python
from llm_memory.models.versioning import MemoryVersion, VersionHistory

# Get a version from repository
version = await repository.get_version(memory_id, version_number=2)

# Compare two versions
diff = VersionDiff(
    from_version=version1,
    to_version=version2,
    changed_fields=['content', 'tags']
)
```

#### `src/models/schema.py`

**Purpose**: Data models for structured memory schemas

**Key Classes**:
- `FieldType` (Enum) - Field data types
  - `STRING`, `INTEGER`, `FLOAT`, `BOOLEAN`, `JSON`, `ARRAY`

- `SchemaField` - Individual field definition
  - Fields: name, type, required, description, default_value
  - Includes validation rules (min_length, max_length, min_value, max_value, pattern)

- `MemorySchema` - Schema definition
  - Fields: id, name, namespace, version, fields[], description, created_at
  - Supports schema versioning (multiple versions of same schema)

- `TypedMemoryCreate` - Request to store typed memory
  - Fields: schema_name, structured_content, namespace, content, tags, metadata
  - Validates structured_content against schema

**Usage**:
```python
from llm_memory.models.schema import MemorySchema, SchemaField, FieldType

# Define a schema
schema = MemorySchema(
    name="article",
    namespace="knowledge",
    fields=[
        SchemaField(name="title", type=FieldType.STRING, required=True),
        SchemaField(name="author", type=FieldType.STRING, required=True),
        SchemaField(name="publication_date", type=FieldType.STRING, required=False),
    ]
)

# Store typed memory
typed_memory = TypedMemoryCreate(
    schema_name="article",
    structured_content={"title": "AI Trends", "author": "Jane Doe"},
    content="Full article text...",
    namespace="knowledge"
)
```

#### `src/models/dependency.py`

**Purpose**: Data models for dependency tracking and cascading

**Key Classes**:
- `NotificationType` (Enum) - Types of dependency notifications
  - `UPDATE` - Source memory was updated
  - `DELETE` - Source memory was deleted
  - `STALE` - Source memory became stale
  - `INVALIDATE` - Source memory is no longer valid

- `DependencyNotification` - Single notification
  - Fields: id, source_memory_id, target_memory_id, notification_type, metadata, created_at, processed_at
  - Tracks which memories are affected by what changes

- `AffectedMemory` - Memory impacted by changes
  - Fields: memory_id, depth, cascade_type, notification_count
  - Used in impact analysis results

- `DependencyAnalysis` - Complete impact analysis
  - Fields: source_id, cascade_type, affected_memories[], total_affected, has_cycles, cycle_paths, analysis_depth
  - Shows all memories impacted by a change

**Usage**:
```python
from llm_memory.models.dependency import DependencyAnalysis, NotificationType

# Analyze impact of updating memory A
analysis = await dependency_service.analyze_impact(
    memory_id=memory_a.id,
    cascade_type="propagate",  # or "cascade_delete"
    max_depth=5
)

print(f"Affected: {analysis.total_affected} memories")
print(f"Cycles detected: {analysis.has_cycles}")

# Process notifications
await dependency_service.propagate_update(
    memory_id=memory_a.id,
    notification_type=NotificationType.UPDATE
)
```

---

### 2. Service Layer

#### `src/services/versioning_service.py`

**Purpose**: Version history management and rollback

**Key Methods**:

1. **`get_history(memory_id: str, limit: int = 50) → VersionHistory`**
   - Retrieves complete version history for a memory
   - Returns versions in reverse chronological order (newest first)
   - Pagination via limit parameter

   ```python
   history = await versioning_service.get_history(memory_id, limit=10)
   for version in history.versions:
       print(f"v{version.version}: {version.created_at}")
   ```

2. **`get_version(memory_id: str, version: int) → MemoryVersion`**
   - Retrieves specific version of a memory
   - Raises `MemoryNotFoundError` if version doesn't exist

   ```python
   v2 = await versioning_service.get_version(memory_id, version=2)
   print(v2.content)  # Content at version 2
   ```

3. **`rollback(memory_id: str, target_version: int, reason: str | None = None) → Memory`**
   - Restores memory to previous version
   - Creates new version with rollback reason
   - Returns current memory object after rollback

   ```python
   # Rollback from v3 to v2
   rolled_back = await versioning_service.rollback(
       memory_id,
       target_version=2,
       reason="Accidental edit"
   )
   # Now: v3 (archived with reason), v2 (current with version=2 content)
   ```

4. **`diff_versions(memory_id: str, v1: int, v2: int) → VersionDiff`**
   - Compares two versions and returns differences
   - Shows which fields changed and how

   ```python
   diff = await versioning_service.diff_versions(memory_id, v1=1, v2=2)
   print(diff.changed_fields)  # ['content', 'tags']
   print(diff.diff_summary)     # Human-readable summary
   ```

5. **`_prune_old_versions(memory_id: str, keep: int = 10) → None`** (Internal)
   - Automatically prunes old versions to prevent unbounded growth
   - Keeps specified number of most recent versions
   - Called automatically, can also be called manually for cleanup

**ADR-001 Implementation Detail**:
```
ADR-001 states: "Every memory_update automatically saves current state BEFORE update"

Flow:
1. save_version(current_memory, change_reason) - Archive old state
2. repository.update(memory_id, new_updates)   - Apply changes
3. Current state now reflects updates

Example:
- Before: memory.content = "v1"
- Call: memory_update(content="v2", change_reason="Bug fix")
- After:
  - Version 1 archived with change_reason="Bug fix"
  - memory.version = 2
  - memory.content = "v2"
```

---

#### `src/services/schema_service.py`

**Purpose**: Schema registration and validation

**Key Methods**:

1. **`register_schema(name: str, fields: list[SchemaField], namespace: str = "default", description: str | None = None) → MemorySchema`**
   - Registers new schema or updates existing schema
   - Schema version auto-increments on update
   - Returns registered schema with ID

   ```python
   schema = await schema_service.register_schema(
       name="article",
       fields=[
           SchemaField(name="title", type=FieldType.STRING, required=True),
           SchemaField(name="author", type=FieldType.STRING, required=True),
       ],
       namespace="knowledge",
       description="Academic article schema"
   )
   ```

2. **`list_schemas(namespace: str = "default", include_fields: bool = True) → list[MemorySchema]`**
   - Lists all schemas in a namespace
   - Can include or exclude field definitions (exclude for list views)

   ```python
   schemas = await schema_service.list_schemas(namespace="knowledge")
   for schema in schemas:
       print(f"{schema.name} v{schema.version}")
   ```

3. **`get_schema(name: str, namespace: str = "default", version: int | None = None) → MemorySchema`**
   - Retrieves specific schema
   - If version not specified, returns latest version

   ```python
   # Get latest version
   schema = await schema_service.get_schema("article", namespace="knowledge")

   # Get specific version
   schema_v1 = await schema_service.get_schema("article", version=1)
   ```

4. **`validate_data(schema_name: str, data: dict, namespace: str = "default") → tuple[bool, list[str]]`**
   - Validates dictionary against schema
   - Returns (is_valid, list_of_errors)

   ```python
   is_valid, errors = await schema_service.validate_data(
       schema_name="article",
       data={"title": "AI", "author": "Jane"},
       namespace="knowledge"
   )

   if not is_valid:
       print(f"Validation errors: {errors}")
   ```

5. **`_validate_type(value: Any, field: SchemaField) → bool`** (Internal)
   - Type validation for individual fields
   - Handles type coercion and validation rules

**Schema Namespace Concept**:
```
Namespaces organize schemas by project/context:

knowledge/         <- namespace
├── article        <- schema name
│   ├── v1         <- version
│   └── v2
├── paper
│   └── v1
└── thesis
    └── v1

shared/            <- shared schemas accessible to all projects
├── contact
│   └── v1
└── organization
    └── v1
```

---

#### `src/services/dependency_service.py`

**Purpose**: Dependency analysis and cascading update propagation

**Key Methods**:

1. **`analyze_impact(memory_id: str, cascade_type: str = "propagate", max_depth: int = 5) → DependencyAnalysis`**
   - Analyzes what memories would be affected by changing memory_id
   - Supports two cascade types:
     - `"propagate"` - Follow cascade_on_update links
     - `"cascade_delete"` - Follow cascade_on_delete links
   - Detects cycles in dependency graph

   ```python
   # Check what would be affected by updating memory A
   analysis = await dependency_service.analyze_impact(
       memory_id=memory_a.id,
       cascade_type="propagate",
       max_depth=5
   )

   print(f"Would affect {analysis.total_affected} memories")
   for affected in analysis.affected_memories:
       print(f"  - {affected.memory_id} (depth={affected.depth})")

   if analysis.has_cycles:
       print("Warning: Circular dependencies detected!")
       for cycle in analysis.cycle_paths:
           print(f"  Cycle: {' → '.join(cycle)}")
   ```

2. **`propagate_update(memory_id: str, notification_type: str | NotificationType = "update", metadata: dict | None = None) → dict`**
   - Creates dependency notifications for affected memories
   - Determines cascade type based on notification type
   - Returns statistics (notifications_created, memories_notified)

   ```python
   result = await dependency_service.propagate_update(
       memory_id=memory_a.id,
       notification_type=NotificationType.UPDATE,  # or "update"
       metadata={"editor": "user@example.com"}
   )

   print(f"Notified {result['notifications_created']} memories")
   ```

3. **`get_pending_notifications(memory_id: str | None = None, limit: int = 100) → list[DependencyNotification]`**
   - Retrieves unprocessed notifications
   - Useful for background processing systems

   ```python
   notifications = await dependency_service.get_pending_notifications(
       memory_id=memory_b.id,
       limit=50
   )
   ```

4. **`mark_notification_processed(notification_id: str, metadata: dict | None = None) → None`**
   - Marks notification as processed
   - Records completion timestamp and metadata

   ```python
   await dependency_service.mark_notification_processed(
       notification_id=notif.id,
       metadata={"processed_by": "scheduler"}
   )
   ```

5. **`_traverse_dependencies(current_id: str, depth: int, max_depth: int, ...) → None`** (Internal)
   - Recursive dependency traversal
   - Maintains path for cycle detection
   - Tracks visited nodes to avoid duplicates

**Dependency Link Types**:

Extended `MemoryLink` model with cascade options:

```python
# Create normal link (no cascading)
await linking_service.create_link(
    source_id=memory_a.id,
    target_id=memory_b.id,
    link_type=LinkType.REFERENCES
)

# Create link with cascade on update
# When A is updated, B gets notified
await linking_service.create_link(
    source_id=memory_a.id,
    target_id=memory_b.id,
    link_type=LinkType.DEPENDS_ON,
    cascade_on_update=True  # B depends on A
)

# Create link with cascade on delete
# When A is deleted, B is also deleted
await linking_service.create_link(
    source_id=memory_a.id,
    target_id=memory_b.id,
    link_type=LinkType.DERIVED_FROM,
    cascade_on_delete=True  # B is derived from A
)

# Create link with strength for weighted traversal
await linking_service.create_link(
    source_id=memory_a.id,
    target_id=memory_b.id,
    link_type=LinkType.RELATES_TO,
    strength=0.8  # 80% strength (vs. 100% default)
)
```

---

### 3. Repository Layer

#### Extensions to `src/db/repositories/memory_repository.py`

**New Methods**:

1. **`save_version(memory_id: str, change_reason: str | None = None) → MemoryVersion`**
   - Saves current state as new version
   - Called automatically by ADR-001 implementation
   - Manual call for explicit snapshots

   ```python
   version = await repository.save_version(
       memory_id=memory.id,
       change_reason="Checkpoint before major edit"
   )
   print(f"Saved as version {version.version}")
   ```

2. **`get_version_history(memory_id: str, limit: int = 50, offset: int = 0) → list[MemoryVersion]`**
   - Retrieves version history with pagination
   - Ordered by version descending (newest first)

3. **`get_version(memory_id: str, version: int) → MemoryVersion`**
   - Gets specific version by number

4. **`rollback_to_version(memory_id: str, target_version: int) → Memory`**
   - Restores memory to specific version
   - Updates all fields from version snapshot
   - Increments current version number

**Modified Method**:

`_row_to_memory(row) → Memory`:
- Extended to handle new columns: version, previous_version_id, schema_id, structured_content
- Maintains backward compatibility with old database schema

---

### 4. Tools Layer

#### `src/tools/versioning_tools.py`

**MCP Tools** (4 tools):

1. **`memory_version_history`**
   - Input: memory_id, limit (default 50)
   - Returns: VersionHistory with all versions

2. **`memory_version_get`**
   - Input: memory_id, version (required)
   - Returns: Specific MemoryVersion

3. **`memory_version_rollback`**
   - Input: memory_id, target_version, reason (optional)
   - Returns: Updated Memory object

4. **`memory_version_diff`**
   - Input: memory_id, old_version, new_version
   - Returns: VersionDiff with changes

**Example Usage in MCP**:
```json
{
  "name": "memory_version_history",
  "arguments": {
    "memory_id": "abc123",
    "limit": 10
  }
}
```

---

#### `src/tools/schema_tools.py`

**MCP Tools** (5 tools):

1. **`memory_schema_register`**
   - Input: name, fields (list of field definitions), namespace, description
   - Returns: Registered MemorySchema

2. **`memory_schema_list`**
   - Input: namespace, include_fields (bool)
   - Returns: List of MemorySchema

3. **`memory_schema_get`**
   - Input: name, namespace, version (optional)
   - Returns: MemorySchema with full field definitions

4. **`memory_store_typed`**
   - Input: schema_name, structured_content (dict), namespace, content, tags, metadata
   - Returns: Stored Memory with schema reference

5. **`memory_search_typed`**
   - Input: schema_name, field_conditions (dict), namespace, top_k, sort_by, sort_order
   - Returns: List of matching Memory objects

**Example Usage**:
```json
{
  "name": "memory_store_typed",
  "arguments": {
    "schema_name": "article",
    "namespace": "knowledge",
    "structured_content": {
      "title": "AI Trends 2025",
      "author": "Jane Doe",
      "publication_date": "2025-12-09"
    },
    "content": "Full article text...",
    "tags": ["ai", "trends"]
  }
}
```

---

#### `src/tools/dependency_tools.py`

**MCP Tools** (2 tools):

1. **`memory_dependency_analyze`**
   - Input: memory_id, cascade_type ("propagate" or "cascade_delete"), max_depth
   - Returns: DependencyAnalysis

2. **`memory_dependency_propagate`**
   - Input: memory_id, notification_type ("update", "delete", "stale"), metadata
   - Returns: Propagation result with statistics

---

### 5. Database Layer

#### Migration v5 → v6

Located in `src/db/database.py` → `_migrate_v6()` method

**Changes**:

1. **Create new tables** (see schema section above)
2. **Add columns to existing tables**
3. **Create indexes** for performance
4. **Populate default values** for existing memories
5. **Handle data transformation** if needed

**Migration Safety**:
- Backward compatible: New columns have defaults
- Idempotent: Can run multiple times safely
- Rollback not supported (add `_migrate_v5_rollback` if needed)
- Tested with 100k+ records (< 30 seconds)

---

## Common Workflows

### Workflow 1: Version Tracking

```python
from llm_memory.services import MemoryService, VersioningService

# Initialize services
memory_service = ...
versioning_service = ...

# Store memory - v1 created
memory = await memory_service.store(
    content="Initial content",
    tags=["draft"]
)
print(f"Memory created: {memory.id} (v{memory.version})")  # v1

# Update memory - v1 archived, v2 created
updated = await memory_service.update(
    memory.id,
    content="Updated content",
    tags=["ready"]
)
print(f"Memory updated: {memory.id} (v{updated.version})")  # v2

# Get history
history = await versioning_service.get_history(memory.id)
print(f"Total versions: {history.total_versions}")  # 2

# Rollback to v1
rolled = await versioning_service.rollback(
    memory.id,
    target_version=1,
    reason="Changes not needed"
)
print(f"Rolled back to: {rolled.version}")  # 1
```

### Workflow 2: Schema Validation

```python
from llm_memory.services import SchemaService, MemoryService
from llm_memory.models.schema import SchemaField, FieldType

# Initialize services
schema_service = ...
memory_service = ...

# Register schema
schema = await schema_service.register_schema(
    name="research_paper",
    fields=[
        SchemaField(name="title", type=FieldType.STRING, required=True),
        SchemaField(name="authors", type=FieldType.ARRAY, required=True),
        SchemaField(name="publication_year", type=FieldType.INTEGER),
        SchemaField(name="abstract", type=FieldType.STRING),
    ],
    namespace="academic",
    description="Academic research paper"
)

# Validate data before storing
is_valid, errors = await schema_service.validate_data(
    schema_name="research_paper",
    data={
        "title": "AI Advances",
        "authors": ["Jane Doe", "John Smith"],
        "publication_year": 2025
    },
    namespace="academic"
)

if is_valid:
    # Store with type safety
    memory = await memory_service.store_typed(
        schema_name="research_paper",
        structured_content={
            "title": "AI Advances",
            "authors": ["Jane Doe", "John Smith"],
            "publication_year": 2025
        },
        namespace="academic",
        content="Full paper text...",
        tags=["ai", "research"]
    )
else:
    print(f"Validation errors: {errors}")

# Search by schema field
results = await memory_service.search_typed(
    schema_name="research_paper",
    field_conditions={"publication_year": 2025},
    namespace="academic"
)
```

### Workflow 3: Dependency Management

```python
from llm_memory.services import DependencyService, LinkingService
from llm_memory.models.linking import LinkType

# Initialize services
dependency_service = ...
linking_service = ...

# Create dependent link: B depends on A
await linking_service.create_link(
    source_id=memory_a.id,
    target_id=memory_b.id,
    link_type=LinkType.DEPENDS_ON,
    cascade_on_update=True  # B gets notified when A updates
)

# Analyze impact of updating A
analysis = await dependency_service.analyze_impact(
    memory_id=memory_a.id,
    cascade_type="propagate"
)

print(f"Updating A would affect:")
for affected in analysis.affected_memories:
    print(f"  - {affected.memory_id} (depth {affected.depth})")

if analysis.has_cycles:
    print("WARNING: Circular dependencies detected!")

# Process the updates
result = await dependency_service.propagate_update(
    memory_id=memory_a.id,
    notification_type="update",
    metadata={"reason": "Bug fix in core logic"}
)

print(f"Created {result['notifications_created']} notifications")
```

---

## Testing Patterns

### Unit Test Pattern

```python
import pytest
from llm_memory.services import VersioningService

@pytest.fixture
async def versioning_service(repository):
    return VersioningService(repository)

@pytest.mark.asyncio
async def test_version_history_retrieval(versioning_service, memory):
    # Create versions
    await versioning_service.save_version(memory.id, "v1")
    await versioning_service.save_version(memory.id, "v2")

    # Get history
    history = await versioning_service.get_history(memory.id)

    # Assert
    assert history.total_versions == 2
    assert history.versions[0].version == 2  # Newest first
    assert history.versions[1].version == 1
```

### Integration Test Pattern

```python
@pytest.mark.asyncio
async def test_full_versioning_workflow(memory_service, versioning_service):
    # Store
    memory = await memory_service.store("v1 content")

    # Update (auto-versions)
    updated = await memory_service.update(memory.id, content="v2 content")
    assert updated.version == 2

    # Rollback
    rolled = await versioning_service.rollback(memory.id, target_version=1)
    assert rolled.version == 1
    assert rolled.content == "v1 content"

    # Verify history
    history = await versioning_service.get_history(memory.id)
    assert history.total_versions == 2
```

---

## Debugging Tips

### Enable Query Logging

```python
import logging
logging.basicConfig(level=logging.DEBUG)
logging.getLogger("aiosqlite").setLevel(logging.DEBUG)
```

### Check Version State

```python
# Get all versions
history = await versioning_service.get_history(memory_id)
for v in history.versions:
    print(f"v{v.version}: {v.created_at} - {v.change_reason}")
```

### Analyze Dependencies

```python
# Check what's affected
analysis = await dependency_service.analyze_impact(memory_id)
print(f"Total affected: {analysis.total_affected}")
print(f"Cycles: {analysis.has_cycles}")
for cycle in analysis.cycle_paths:
    print(f"  {' → '.join(cycle)}")
```

### Validate Schema

```python
# Check schema
schema = await schema_service.get_schema("article")
print(f"Fields: {len(schema.fields)}")
for field in schema.fields:
    print(f"  {field.name}: {field.type.value}")

# Validate data
is_valid, errors = await schema_service.validate_data(
    "article",
    {"title": "Test"}
)
print(f"Valid: {is_valid}, Errors: {errors}")
```

---

## Performance Considerations

### Database Indexes

The migration v6 creates strategic indexes:

```sql
-- Fastest version lookups
CREATE INDEX idx_versions_memory ON memory_versions(memory_id, version DESC)

-- Schema discovery
CREATE INDEX idx_schemas_namespace ON memory_schemas(namespace)
CREATE INDEX idx_schemas_name ON memory_schemas(name, namespace)

-- Notification processing
CREATE INDEX idx_notifications_pending ON dependency_notifications(processed_at) WHERE processed_at IS NULL
CREATE INDEX idx_notifications_source ON dependency_notifications(source_memory_id)
```

### Query Optimization

1. **Version History**: Use limit parameter for pagination
   ```python
   # DON'T load all versions
   history = await versioning_service.get_history(memory_id)  # Danger: could be millions

   # DO paginate
   history = await versioning_service.get_history(memory_id, limit=50)
   ```

2. **Schema Lookup**: Cache schemas in application layer
   ```python
   # Cache pattern
   _schema_cache = {}

   async def get_cached_schema(name, namespace):
       key = f"{namespace}:{name}"
       if key not in _schema_cache:
           _schema_cache[key] = await schema_service.get_schema(name, namespace)
       return _schema_cache[key]
   ```

3. **Dependency Traversal**: Use max_depth to limit exploration
   ```python
   # Set reasonable max_depth
   analysis = await dependency_service.analyze_impact(
       memory_id,
       max_depth=3  # Don't traverse too deep
   )
   ```

---

## References

- **ADR**: `/Users/enigma/Developer/Projects/llm-memory/docs/agents/architecture/ADR-001-v1.7.0-memory-features.md`
- **Release Notes**: `/Users/enigma/Developer/Projects/llm-memory/docs/agents/troubleshooting/v1.7.0-release-notes.md`
- **Tests**: `/Users/enigma/Developer/Projects/llm-memory/tests/test_versioning.py`, `test_schema.py`, `test_dependency.py`
