# v1.1.0 Implementation Guidelines

**Status:** Active
**Version:** 1.1.0
**Last Updated:** 2025-12-06
**Applies To:** Services, Tools, Repository

---

## Architecture Patterns

### 1. Service Layer Pattern

**Purpose:** Encapsulate business logic separate from data access

**Pattern:**
```python
class SomeService:
    def __init__(self, repository: SomeRepository, db: Database):
        self.repository = repository
        self.db = db

    async def business_operation(self, ...):
        """Pure business logic - no transaction handling"""
        # 1. Get data from repository
        # 2. Transform/process
        # 3. Call repository for updates
        # 4. Return result
```

**Rules:**
- ✅ Services contain business logic
- ✅ Services delegate data access to Repository
- ✅ Services can call other Services (but be careful of circular deps)
- ❌ Services do NOT open transactions directly
- ❌ Services do NOT write SQL
- ❌ Services do NOT hardcode database queries

---

### 2. Repository Pattern for Transactions

**Purpose:** Centralize transaction management

**Pattern:**
```python
class SomeRepository:
    async def create(self, item: SomeModel, use_transaction: bool = True) -> SomeModel:
        """
        Create operation with optional transaction wrapping.

        Args:
            item: Model to create
            use_transaction: If True, wraps in transaction. If False, assumes
                           caller manages transaction.
        """
        if use_transaction:
            async with self.db.transaction():
                return await self._create_internal(item)
        else:
            return await self._create_internal(item)

    async def _create_internal(self, item: SomeModel) -> SomeModel:
        """Internal implementation without transaction."""
        # Actual SQL logic
```

**Rules:**
- ✅ All data-modifying operations accept `use_transaction` parameter
- ✅ Default to `use_transaction=True` for single operations
- ✅ Pass `use_transaction=False` when called from batch operations
- ❌ Do NOT nest transactions
- ❌ Do NOT leave transactions open across method calls

**When to use use_transaction=False:**
```python
# ✅ Correct: Batch operation manages transaction
async with self.db.transaction():
    for item in items:
        await self.repository.create(item, use_transaction=False)

# ❌ Wrong: Nested transactions
async def batch_create(items):
    async with self.db.transaction():
        for item in items:
            await self.repository.create(item)  # Opens another transaction!
```

---

### 3. API Purity Pattern

**Purpose:** Distinguish between pure computation and async operations

**Pattern:**
```python
class ImportanceService:
    # Pure calculation function (sync)
    def calculate_score(
        self,
        access_count: int,
        last_accessed_at: datetime | None,
        created_at: datetime
    ) -> float:
        """Pure calculation - no I/O, no state changes."""
        # Pure math operations
        return score

    # Async operation function
    async def calculate_and_update_score(self, memory_id: str) -> float:
        """Fetches data, calculates, and updates - async operation."""
        stats = await self.repository.get_access_stats(memory_id)
        score = self.calculate_score(
            access_count=stats['access_count'],
            last_accessed_at=stats['last_accessed_at'],
            created_at=stats['created_at']
        )
        await self.repository.update_importance(memory_id, score, ...)
        return score
```

**Rules:**
- ✅ Pure functions are sync (no await)
- ✅ Async operations explicitly state data fetching
- ✅ Test pure functions without mocking
- ✅ Test async operations with mock repository
- ❌ Don't make calculation functions async if they're pure
- ❌ Don't make I/O operations sync

---

### 4. Batch Operation Pattern

**Purpose:** Handle bulk operations efficiently

**Pattern:**
```python
@dataclass
class BatchResult:
    success_count: int
    error_count: int
    created_ids: list[str]
    errors: list[dict]

async def batch_store(
    self,
    items: list[dict],
    on_error: str = "skip"  # "skip" or "rollback"
) -> BatchResult:
    """
    Store multiple memories.

    Args:
        items: List of memory dictionaries
        on_error: "skip" continues on error, "rollback" aborts all

    Returns:
        BatchResult with success count and errors
    """
    if on_error == "rollback":
        return await self._batch_store_rollback(items)
    else:
        return await self._batch_store_skip(items)

async def _batch_store_rollback(self, items: list[dict]) -> BatchResult:
    """All-or-nothing batch store."""
    try:
        async with self.db.transaction():
            created_ids = []
            for item in items:
                # Validation happens here, can raise
                memory = Memory(**item)
                created = await self.repository.create(
                    memory, use_transaction=False
                )
                created_ids.append(created.id)

        return BatchResult(
            success_count=len(created_ids),
            error_count=0,
            created_ids=created_ids,
            errors=[]
        )
    except Exception as e:
        return BatchResult(
            success_count=0,
            error_count=len(items),
            created_ids=[],
            errors=[{"error": str(e)}]
        )

async def _batch_store_skip(self, items: list[dict]) -> BatchResult:
    """Continue on error batch store."""
    result = BatchResult(0, 0, [], [])

    for idx, item in enumerate(items):
        try:
            memory = Memory(**item)
            created = await self.repository.create(
                memory, use_transaction=True
            )
            result.success_count += 1
            result.created_ids.append(created.id)
        except Exception as e:
            result.error_count += 1
            result.errors.append({
                "index": idx,
                "error": str(e)
            })

    return result
```

**Rules:**
- ✅ Batch operations accept `on_error` parameter
- ✅ "rollback" mode wraps entire batch in transaction
- ✅ "skip" mode creates individual transactions
- ✅ Always return BatchResult with detailed error info
- ✅ Pass `use_transaction=False` to repo when in external transaction
- ❌ Don't silently ignore errors in skip mode
- ❌ Don't wrap skip mode in transaction (defeats "skip" purpose)

---

### 5. Access Logging Pattern

**Purpose:** Track memory usage for importance scoring

**Pattern:**
```python
async def get(self, memory_id: str) -> Memory | None:
    memory = await self.repository.find_by_id(memory_id)

    if memory:
        # Always log access
        await self.repository.log_access(memory_id, 'get')

        # Update access stats
        await self.repository.update_importance(
            memory_id,
            memory.importance_score,
            memory.access_count + 1,
            datetime.now(timezone.utc)
        )

    return memory

async def search(self, query: str, ...) -> list[SearchResult]:
    results = await self.repository.search(query, ...)

    # Log search for each result
    for result in results:
        await self.repository.log_access(result.memory_id, 'search')

    return results
```

**Rules:**
- ✅ Log access on: get, search, batch_get operations
- ✅ Update both access_count and last_accessed_at
- ✅ Log after successful retrieval
- ❌ Don't log failed accesses
- ❌ Don't update importance directly (use update_importance method)

---

## Testing Patterns

### 1. Service Testing Pattern

```python
@pytest.mark.asyncio
async def test_service_operation():
    """Test service business logic with mocked repository."""
    # Arrange
    mock_repo = AsyncMock(spec=SomeRepository)
    mock_repo.find_by_id.return_value = Memory(id="test", ...)
    service = SomeService(mock_repo, MagicMock())

    # Act
    result = await service.operation("test")

    # Assert
    assert result is not None
    mock_repo.find_by_id.assert_called_once_with("test")
```

### 2. Repository Testing Pattern

```python
@pytest.mark.asyncio
async def test_repository_with_transaction():
    """Test repository with real database."""
    db = Database(":memory:")
    await db.initialize()
    repo = SomeRepository(db)

    # Test with transaction
    item = await repo.create(test_item, use_transaction=True)
    assert item.id is not None

    # Verify data persisted
    found = await repo.find_by_id(item.id)
    assert found is not None
```

### 3. Batch Operation Testing Pattern

```python
@pytest.mark.asyncio
async def test_batch_store_rollback_on_error():
    """Test batch store rollback mode."""
    items = [
        {"id": "1", "content": "valid"},
        {"id": "2", "content_type": "invalid"},  # Will fail
    ]

    result = await service.batch_store(items, on_error="rollback")

    assert result.success_count == 0
    assert result.error_count > 0

    # Verify nothing was stored
    assert await repo.find_by_id("1") is None
```

### 4. Integration Testing Pattern

```python
@pytest.mark.asyncio
async def test_consolidation_full_flow():
    """Test consolidation with real service stack."""
    db = Database(":memory:")
    await db.initialize()

    # Create real services
    memory_repo = MemoryRepository(db)
    memory_service = MemoryService(memory_repo, db)
    consolidation_service = ConsolidationService(memory_repo)

    # Store initial memories
    mem1 = await memory_service.store(Memory(...))
    mem2 = await memory_service.store(Memory(...))

    # Consolidate
    result = await consolidation_service.consolidate(
        [mem1.id, mem2.id],
        preserve_originals=False
    )

    # Verify consolidation
    assert result.id is not None
    assert await memory_service.get(mem1.id) is None  # Original deleted
    assert await memory_service.get(mem2.id) is None
    assert await memory_service.get(result.id) is not None
```

---

## Common Mistakes to Avoid

### Mistake 1: Nested Transactions
```python
# ❌ WRONG
async def batch_update(items):
    async with self.db.transaction():  # Opens transaction
        for item in items:
            await self.repository.update(item)  # Opens another!

# ✅ CORRECT
async def batch_update(items):
    async with self.db.transaction():
        for item in items:
            await self.repository.update(item, use_transaction=False)
```

### Mistake 2: Making Pure Functions Async
```python
# ❌ WRONG
async def calculate_score(self, access_count, last_accessed, created):
    # Pure math - no I/O
    return 0.5

# ✅ CORRECT
def calculate_score(self, access_count, last_accessed, created) -> float:
    # Pure math - no await needed
    return 0.5
```

### Mistake 3: Silently Failing in Batch Operations
```python
# ❌ WRONG
async def batch_store(self, items):
    for item in items:
        try:
            await self.repository.create(item)
        except:
            pass  # Silent failure - no error tracking!
    return {"created": len(items)}

# ✅ CORRECT
async def batch_store(self, items, on_error="skip"):
    result = BatchResult(0, 0, [], [])
    for idx, item in enumerate(items):
        try:
            created = await self.repository.create(item)
            result.success_count += 1
            result.created_ids.append(created.id)
        except Exception as e:
            result.error_count += 1
            result.errors.append({"index": idx, "error": str(e)})
    return result
```

### Mistake 4: Forgetting Access Logging
```python
# ❌ WRONG
async def get(self, memory_id):
    return await self.repository.find_by_id(memory_id)
    # No access logging - importance scoring won't work!

# ✅ CORRECT
async def get(self, memory_id):
    memory = await self.repository.find_by_id(memory_id)
    if memory:
        await self.repository.log_access(memory_id, 'get')
    return memory
```

---

## Performance Guidelines

### 1. Batch Size Limits
- Maximum batch_store: 100 items
- Maximum consolidation: 50 memories
- Minimum consolidation: 2 memories

### 2. Query Optimization
- Use indexes for: `memory_id`, `created_at`, `importance_score`
- Use FTS5 for keyword search (not LIKE)
- Limit results in hybrid search before RRF ranking

### 3. Access Log Management
- Retain only last 30 days
- Run `cleanup_access_logs()` weekly
- Don't retrieve full history for scoring (use aggregates)

### 4. Transaction Duration
- Keep transactions short (< 1 second)
- Compute expensive operations before transaction
- Avoid complex joins in transactions

---

## Database Schema Rules

### 1. Column Naming
- Use snake_case for all columns
- Timestamps: `_at` suffix (created_at, last_accessed_at)
- Counts: `_count` suffix (access_count)
- Scores: `_score` suffix (importance_score)

### 2. Data Types
- IDs: TEXT with NOT NULL
- Timestamps: DATETIME with timezone awareness
- Scores: FLOAT with [0.0, 1.0] range
- Counts: INTEGER with >= 0

### 3. Foreign Keys
- Always include `ON DELETE CASCADE` for cleanup
- Prefer soft deletes with timestamp column
- Index foreign key columns

---

## Code Style (Python)

### 1. Type Hints
```python
# ✅ Required for all public methods
async def store(self, memory: Memory) -> Memory:
    ...

# ✅ Use union types
def calculate(self, value: int | float) -> float:
    ...

# ✅ Use Optional for nullable
async def find(self, id: str) -> Memory | None:
    ...
```

### 2. Docstrings
```python
async def consolidate(
    self,
    memory_ids: list[str],
    preserve_originals: bool = True,
) -> Memory:
    """
    Consolidate multiple memories into one.

    Args:
        memory_ids: List of memory IDs to consolidate
        preserve_originals: If False, delete original memories

    Returns:
        New consolidated memory

    Raises:
        ValueError: If fewer than 2 or more than 50 memories
    """
```

### 3. Error Handling
```python
# ✅ Specific exceptions
try:
    await repository.create(item)
except ValueError as e:
    logger.error("Invalid memory: %s", e)
    raise

# ❌ Generic exceptions
try:
    await repository.create(item)
except Exception:
    pass
```

---

## References

- Architecture: `docs/agents/architecture/ADR-001-v1.1.0-features.md`
- Issues & Solutions: `docs/agents/troubleshooting/v1.1.0-implementation-issues.md`
- Test Suite: `tests/test_*.py`
